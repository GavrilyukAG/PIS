{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2gX3tAgPp6V"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0K5iEc_RWvN"
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_classes = 10\n",
    "epochs = 32\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'tmp/keras_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kLgwH_jBXH_H",
    "outputId": "e6f2897c-5b3b-4a51-bd06-00087fe5ebf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/alexandr/Учеба/Мага/giis/lab3',\n",
       " '/Users/alexandr/Учеба/Мага/giis/lab3/tmp/keras_data')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd(), save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Ks3uqaWmQt4L",
    "outputId": "19226800-9f0f-421b-8f39-1060921f1c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFuIAqxpRSg5"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQk_nn3NRc_t"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "id": "uqJtQVpBUGAB",
    "outputId": "62832b8d-d064-4e01-f2a6-1ae54461ad42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 2.0098 - acc: 0.2643Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 163us/sample - loss: 1.7490 - acc: 0.3997\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 2.0096 - acc: 0.2645 - val_loss: 1.7552 - val_acc: 0.3997\n",
      "Epoch 2/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.7759 - acc: 0.3554Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 162us/sample - loss: 1.5513 - acc: 0.4498\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.7759 - acc: 0.3554 - val_loss: 1.5730 - val_acc: 0.4498\n",
      "Epoch 3/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.6689 - acc: 0.3929Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 3s 260us/sample - loss: 1.5252 - acc: 0.4604\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 1.6688 - acc: 0.3928 - val_loss: 1.5122 - val_acc: 0.4604\n",
      "Epoch 4/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.6104 - acc: 0.4161Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 186us/sample - loss: 1.4389 - acc: 0.4954\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 1.6105 - acc: 0.4160 - val_loss: 1.4323 - val_acc: 0.4954\n",
      "Epoch 5/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.5681 - acc: 0.4322Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 177us/sample - loss: 1.4363 - acc: 0.4965\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 1.5681 - acc: 0.4323 - val_loss: 1.4101 - val_acc: 0.4965\n",
      "Epoch 6/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.5322 - acc: 0.4475Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 182us/sample - loss: 1.4356 - acc: 0.5000\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 1.5321 - acc: 0.4477 - val_loss: 1.3838 - val_acc: 0.5000\n",
      "Epoch 7/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.5039 - acc: 0.4577Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 180us/sample - loss: 1.4300 - acc: 0.5010\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 1.5034 - acc: 0.4579 - val_loss: 1.3770 - val_acc: 0.5010\n",
      "Epoch 8/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.4754 - acc: 0.4719Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 152us/sample - loss: 1.3688 - acc: 0.5210\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 1.4754 - acc: 0.4719 - val_loss: 1.3200 - val_acc: 0.5210\n",
      "Epoch 9/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.4541 - acc: 0.4785Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 172us/sample - loss: 1.3483 - acc: 0.5334\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 1.4539 - acc: 0.4785 - val_loss: 1.3004 - val_acc: 0.5334\n",
      "Epoch 10/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.4252 - acc: 0.4870Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 178us/sample - loss: 1.3503 - acc: 0.5262\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 1.4250 - acc: 0.4873 - val_loss: 1.2980 - val_acc: 0.5262\n",
      "Epoch 11/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.4057 - acc: 0.4965Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 176us/sample - loss: 1.3368 - acc: 0.5367\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 1.4057 - acc: 0.4965 - val_loss: 1.2823 - val_acc: 0.5367\n",
      "Epoch 12/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3864 - acc: 0.5041Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 208us/sample - loss: 1.2713 - acc: 0.5568\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 1.3863 - acc: 0.5041 - val_loss: 1.2311 - val_acc: 0.5568\n",
      "Epoch 13/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3709 - acc: 0.5104Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 174us/sample - loss: 1.2496 - acc: 0.5678\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 1.3708 - acc: 0.5104 - val_loss: 1.2224 - val_acc: 0.5678\n",
      "Epoch 14/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3572 - acc: 0.5135Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 172us/sample - loss: 1.2219 - acc: 0.5803\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 1.3572 - acc: 0.5135 - val_loss: 1.1801 - val_acc: 0.5803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3385 - acc: 0.5211Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 172us/sample - loss: 1.2148 - acc: 0.5831\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 1.3384 - acc: 0.5212 - val_loss: 1.1914 - val_acc: 0.5831\n",
      "Epoch 16/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.3309 - acc: 0.5237Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 172us/sample - loss: 1.2122 - acc: 0.5820\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 1.3308 - acc: 0.5237 - val_loss: 1.2002 - val_acc: 0.5820\n",
      "Epoch 17/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3187 - acc: 0.5311Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 172us/sample - loss: 1.1681 - acc: 0.5926\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 1.3187 - acc: 0.5311 - val_loss: 1.1482 - val_acc: 0.5926\n",
      "Epoch 18/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3129 - acc: 0.5330Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 181us/sample - loss: 1.1833 - acc: 0.5876\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 1.3127 - acc: 0.5330 - val_loss: 1.1566 - val_acc: 0.5876\n",
      "Epoch 19/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.2959 - acc: 0.5389Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 180us/sample - loss: 1.2054 - acc: 0.5819\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1.2961 - acc: 0.5389 - val_loss: 1.1639 - val_acc: 0.5819\n",
      "Epoch 20/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2928 - acc: 0.5392Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 169us/sample - loss: 1.1415 - acc: 0.6035\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 1.2927 - acc: 0.5392 - val_loss: 1.1291 - val_acc: 0.6035\n",
      "Epoch 21/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2836 - acc: 0.5435Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 170us/sample - loss: 1.1798 - acc: 0.5954\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 1.2836 - acc: 0.5435 - val_loss: 1.1581 - val_acc: 0.5954\n",
      "Epoch 22/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.2822 - acc: 0.5452Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 1s 149us/sample - loss: 1.1557 - acc: 0.6061\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 1.2821 - acc: 0.5451 - val_loss: 1.1252 - val_acc: 0.6061\n",
      "Epoch 23/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2654 - acc: 0.5501Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 203us/sample - loss: 1.1868 - acc: 0.5946\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 1.2655 - acc: 0.5500 - val_loss: 1.1657 - val_acc: 0.5946\n",
      "Epoch 24/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2593 - acc: 0.5506Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 160us/sample - loss: 1.1436 - acc: 0.6064\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2595 - acc: 0.5505 - val_loss: 1.1359 - val_acc: 0.6064\n",
      "Epoch 25/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2605 - acc: 0.5517Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 168us/sample - loss: 1.1426 - acc: 0.5994\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2603 - acc: 0.5518 - val_loss: 1.1258 - val_acc: 0.5994\n",
      "Epoch 26/32\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.2518 - acc: 0.5551Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 2s 159us/sample - loss: 1.1866 - acc: 0.5866\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 1.2518 - acc: 0.5550 - val_loss: 1.1696 - val_acc: 0.5866\n",
      "Epoch 27/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2455 - acc: 0.5577Epoch 1/32\n",
      "10000/1000 [============================================================================================================================================================================================================================================================================================================] - 1s 149us/sample - loss: 1.1749 - acc: 0.5992\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 1.2456 - acc: 0.5576 - val_loss: 1.1487 - val_acc: 0.5992\n",
      "Epoch 28/32\n",
      " 656/1000 [==================>...........] - ETA: 14s - loss: 1.2412 - acc: 0.5607"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-466196879d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         workers=1)\n\u001b[0m",
      "\u001b[0;32m~/Учеба/Мага/giis/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/Учеба/Мага/giis/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Учеба/Мага/giis/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Учеба/Мага/giis/env/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/Учеба/Мага/giis/env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "      rotation_range = 20,\n",
    "      width_shift_range = 0.2,\n",
    "      height_shift_range = 0.2,\n",
    "      horizontal_flip = True\n",
    "    )\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "MrwwSuuNXes4",
    "outputId": "3178798c-71e1-45b1-9a4e-6fe5df78e583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /Users/alexandr/Учеба/Мага/giis/lab3/tmp/keras_data\n",
      "10000/10000 [==============================] - 2s 194us/sample - loss: 1.3353 - acc: 0.5214\n",
      "Test loss: 1.3352680932998657\n",
      "Test accuracy: 0.5214\n"
     ]
    }
   ],
   "source": [
    "# model_path = os.path.join(save_dir, model_name)\n",
    "# model.save(model_path)\n",
    "model.save(save_dir)\n",
    "print('Saved trained model at {}'.format(save_dir))\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab3_cnn_kp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
